{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a630f3f8-9911-481f-a4da-8c2628ed9672",
   "metadata": {},
   "source": [
    "## 初期設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfd7a81-31c1-4dbb-8e9d-22baf1f784c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = '8248_ImageFeature-Effnetb0TorchV_EvalGMM' # ファイル名とそろえる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d04a62b-b617-424f-bee4-183b05293fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.io as sio\n",
    "from scipy.signal import resample\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import lightgbm as lgb\n",
    "import scipy.signal as signal\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.signal import welch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import timm\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40243d0f-d84e-4b8b-b322-b93c34936270",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = sio.loadmat('dataset/train.mat')\n",
    "test = sio.loadmat('dataset/test.mat')\n",
    "reference = sio.loadmat('dataset/reference.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753b69f6-7687-458c-889f-89aacdf72561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n16個の変数はインデックスの小さい順番から順番に以下のようなデータが配列されている.\\n- TibialisAnterior Right(脛骨前筋 右)\\n- TibialisAnterior Left(脛骨前筋 左)\\n- GastrocnemiusLateralis Right(外側広筋 右)\\n- GastrocnemiusLateralis Left(外側広筋 左)\\n- QuadricepsRectusFemoris Right(大腿四頭筋 直腿筋 右)\\n- QuadricepsRectusFemoris Left(大腿四頭筋 直腿筋 左)\\n- QuadricepsVastusLateralis Right(大腿四頭筋 外側広筋 右)\\n- QuadricepsVastusLateralis Left(大腿四頭筋 外側広筋 左)\\n- Semitendinosus Right(半腱様筋 右)\\n- Semitendinosus Left(半腱様筋 左)\\n- GluteusMaximus Right(大殿筋 右)\\n- GluteusMaximus Left(大殿筋 左)\\n- ErectorSpinaeIliocostalis Right(脊柱起立筋 右)\\n- ErectorSpinaeIliocostalis Left(脊柱起立筋 左)\\n- DeltoideusMedius Right(三角筋 右)\\n- DeltoideusMedius Left(三角筋 左)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筋電位データの特徴量の名前です\n",
    "feature_name = ['TA R', 'TA L', 'LG R', 'LG L', 'RF R', 'RF L', 'VL R', 'VL L', 'ST R',\n",
    "                'ST L', 'GMAX R', 'GMAX L', 'EMI R', 'EMI L', 'DEL R', 'DEL L']\n",
    "\n",
    "\"\"\"\n",
    "16個の変数はインデックスの小さい順番から順番に以下のようなデータが配列されている.\n",
    "- TibialisAnterior Right(脛骨前筋 右)\n",
    "- TibialisAnterior Left(脛骨前筋 左)\n",
    "- GastrocnemiusLateralis Right(外側広筋 右)\n",
    "- GastrocnemiusLateralis Left(外側広筋 左)\n",
    "- QuadricepsRectusFemoris Right(大腿四頭筋 直腿筋 右)\n",
    "- QuadricepsRectusFemoris Left(大腿四頭筋 直腿筋 左)\n",
    "- QuadricepsVastusLateralis Right(大腿四頭筋 外側広筋 右)\n",
    "- QuadricepsVastusLateralis Left(大腿四頭筋 外側広筋 左)\n",
    "- Semitendinosus Right(半腱様筋 右)\n",
    "- Semitendinosus Left(半腱様筋 左)\n",
    "- GluteusMaximus Right(大殿筋 右)\n",
    "- GluteusMaximus Left(大殿筋 左)\n",
    "- ErectorSpinaeIliocostalis Right(脊柱起立筋 右)\n",
    "- ErectorSpinaeIliocostalis Left(脊柱起立筋 左)\n",
    "- DeltoideusMedius Right(三角筋 右)\n",
    "- DeltoideusMedius Left(三角筋 左)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a811758e-4364-4196-ba5f-09af1e6e4429",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = \"output/\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(os.path.join(output_folder, exp_name), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "def2f4c2-4ec9-498d-bc61-c01cf53216c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 乱数シードの設定\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed = 42\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed137432-3079-4765-9daa-00ad33457e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# データ保存の例\n",
    "def save_data_with_pickle(data, file_path):\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "\n",
    "# データ読み込みの例\n",
    "def load_data_with_pickle(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa41129c-4616-4768-84f5-615857ec5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_num = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee985f38-6cc1-44ec-aa67-3700311e9e77",
   "metadata": {},
   "source": [
    "## 画像データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75cf07ee-efc2-4a40-a7e7-b6545971ef6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 1000, 16)\n",
      "(319, 30, 3)\n",
      "(300, 1000, 16)\n",
      "(300, 30, 3)\n",
      "(320, 1000, 16)\n",
      "(320, 30, 3)\n",
      "(320, 1000, 16)\n",
      "(320, 30, 3)\n"
     ]
    }
   ],
   "source": [
    "for user_id in [\"0001\", \"0002\", \"0003\", \"0004\"]:\n",
    "    x_array = train[user_id][0][0][0]\n",
    "    y_array = train[user_id][0][0][1]\n",
    "    \n",
    "    # 形状を変更 (例: (319, 30, 3) -> (319, 3, 30))\n",
    "    x_array = x_array.transpose(0, 2, 1)\n",
    "    y_array = y_array.transpose(0, 2, 1)\n",
    "    print(x_array.shape)  # デバッグ出力用\n",
    "    print(y_array.shape)  # デバッグ出力用\n",
    "\n",
    "    # 連結用リスト\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for i, x_arr in enumerate(x_array):\n",
    "        x_df = pd.DataFrame()\n",
    "\n",
    "        # DataFrameを作成\n",
    "        for j, col in enumerate(feature_name):\n",
    "            x_df[f\"{col}\"] = x_arr[:, j]\n",
    "        \n",
    "        # DataFrameをリストに追加\n",
    "        x_list.append(x_df)\n",
    "\n",
    "    for i, y_arr in enumerate(y_array):\n",
    "        y_df = pd.DataFrame()\n",
    "\n",
    "        # DataFrameを作成\n",
    "        for j, col in enumerate([\"vel_x\", \"vel_y\", \"vel_z\"]):\n",
    "            y_df[f\"{col}\"] = y_arr[:, j]\n",
    "        \n",
    "        # DataFrameをリストに追加\n",
    "        y_list.append(y_df)\n",
    "        \n",
    "    # 各ユーザーのDataFrameを縦方向に連結\n",
    "    combined_x_df = pd.concat(x_list, ignore_index=True)    \n",
    "    combined_y_df = pd.concat(y_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bd5b50b-e68e-4d17-b29e-2b8e3b25e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込みと前処理\n",
    "def load_data_labels(output_folder, exp_name):\n",
    "    labels = []\n",
    "\n",
    "    for user_id in [\"0001\", \"0002\", \"0003\", \"0004\"]:\n",
    "        y_array = train[user_id][0][0][1]\n",
    "        y_array = y_array.transpose(0, 2, 1)\n",
    "        \n",
    "        for i in range(y_array.shape[0]):\n",
    "            labels.append(y_array[i].reshape(-1))  # 90次元ベクトルに変換\n",
    "\n",
    "    for user_id in [\"0005\"]:\n",
    "        y_array = reference[user_id][0][0][1]\n",
    "        y_array = y_array.transpose(0, 2, 1)\n",
    "        \n",
    "        for i in range(y_array.shape[0]):\n",
    "            labels.append(y_array[i].reshape(-1))  # 90次元ベクトルに変換\n",
    "    \n",
    "    # ここでfeaturesとlabelsをNumpy配列に変換\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bc2837f-0ff0-4582-8cdd-251b08072f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解ラベルの作成\n",
    "labels = load_data_labels(output_folder, exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e178c4bd-cf01-4654-a9c2-792ae5f97c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 速度データから特徴量ベクトル作成\n",
    "vel_features = []\n",
    "print(len(labels))\n",
    "for i in range(len(labels)):\n",
    "    vel_x = labels[i][0::3]\n",
    "    vel_y = labels[i][1::3]\n",
    "    vel_z = labels[i][2::3]\n",
    "\n",
    "    acc_x = np.diff(vel_x)\n",
    "    acc_y = np.diff(vel_y)\n",
    "    acc_z = np.diff(vel_z)\n",
    "\n",
    "    sum_x = np.sum(vel_x)\n",
    "    sum_y = np.sum(vel_y)\n",
    "    sum_z = np.sum(vel_z)\n",
    "\n",
    "    diff_x = vel_x[0] - vel_x[29]\n",
    "    diff_y = vel_y[0] - vel_y[29]\n",
    "    diff_z = vel_z[0] - vel_z[29]\n",
    "    \n",
    "    feature_vector = np.concatenate([vel_x, vel_y, vel_z, [sum_x, sum_y, sum_z]])\n",
    "    vel_features.append(feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f392314-b90a-4f7e-92f9-c76fff8fcd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCAで次元削減\n",
    "pca = PCA(n_components=10)\n",
    "principal_components = pca.fit_transform(vel_features)\n",
    "\n",
    "# Gaussian Mixture Modelを用いて3クラスに分類\n",
    "from sklearn.mixture import GaussianMixture\n",
    "gmm = GaussianMixture(n_components=3, random_state=seed)\n",
    "gmm.fit(principal_components)\n",
    "labels_probs = gmm.predict_proba(principal_components)  # 各クラスの確率\n",
    "labels_gmm = gmm.predict(principal_components)  # 各データポイントのクラス\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd944266-23fa-46a6-b169-d502bf386a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "636\n",
      "431\n",
      "512\n",
      "1579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 2, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(principal_components[labels_gmm == 0, 0]))\n",
    "print(len(principal_components[labels_gmm == 1, 0]))\n",
    "print(len(principal_components[labels_gmm == 2, 0]))\n",
    "print(len(labels_gmm))\n",
    "labels_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b823a7b-e2d3-4061-8606-6da6fbcf189b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.86865937e-250, 1.00000000e+000, 4.08046809e-027],\n",
       "       [1.00000000e+000, 3.94527460e-286, 3.62326933e-047],\n",
       "       [1.00000000e+000, 5.63792605e-207, 1.21654599e-075],\n",
       "       ...,\n",
       "       [7.84428548e-112, 1.61659361e-045, 1.00000000e+000],\n",
       "       [1.00000000e+000, 2.77156674e-231, 3.64891571e-100],\n",
       "       [1.71210341e-310, 1.00000000e+000, 1.31253177e-010]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a9af86-cdb6-424b-8faf-d0ce6cfc6a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8e65ba8-a02a-4933-9891-c4d70cf10afa",
   "metadata": {},
   "source": [
    "## 判定結果からクラス分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "398cac61-63e7-44e7-adb3-affb67d92c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name_woCatg = '8227_ImageFeature-Effnetb0TorchV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "967c6cf9-7545-4205-a8d3-e77d08ef9562",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output//8227_ImageFeature-Effnetb0TorchV/train_0001.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m test_path_woCatg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_name_woCatg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/test_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 訓練データの読み込み\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m train_data_woCatg \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path_woCatg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m test_data_woCatg \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(test_path_woCatg)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 予測値のみ抽出し、列名にモデル名を追加\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output//8227_ImageFeature-Effnetb0TorchV/train_0001.csv'"
     ]
    }
   ],
   "source": [
    "def extract_features(vel_x, vel_y, vel_z):\n",
    "    acc_x = np.diff(vel_x)\n",
    "    acc_y = np.diff(vel_y)\n",
    "    acc_z = np.diff(vel_z)\n",
    "\n",
    "    sum_x = np.sum(vel_x)\n",
    "    sum_y = np.sum(vel_y)\n",
    "    sum_z = np.sum(vel_z)\n",
    "    \n",
    "    feature_vector = np.concatenate([vel_x, vel_y, vel_z, [sum_x, sum_y, sum_z]])\n",
    "    return feature_vector\n",
    "\n",
    "# ユーザーごとに処理\n",
    "all_train_classes = []\n",
    "all_train_classes_true = []\n",
    "all_test_classes = []\n",
    "\n",
    "all_train_probs = []\n",
    "all_train_probs_true = []\n",
    "all_test_probs = []\n",
    "for user_id in [\"0001\", \"0002\", \"0003\", \"0004\", \"0005\"]:\n",
    "\n",
    "    # 各モデルのデータを結合\n",
    "    train_path_woCatg = f\"{output_folder}/{exp_name_woCatg}/train_{user_id}.csv\"\n",
    "    test_path_woCatg = f\"{output_folder}/{exp_name_woCatg}/test_{user_id}.csv\"\n",
    "    \n",
    "    # 訓練データの読み込み\n",
    "    train_data_woCatg = pd.read_csv(train_path_woCatg)\n",
    "    test_data_woCatg = pd.read_csv(test_path_woCatg)\n",
    "    \n",
    "    # 予測値のみ抽出し、列名にモデル名を追加\n",
    "    train_predicted_woCatg = train_data_woCatg.filter(regex='_predicted')\n",
    "    train_predicted_woCatg_true = train_data_woCatg.loc[:, ~train_data_woCatg.columns.str.contains('_predicted')]\n",
    "    test_predicted_woCatg = test_data_woCatg.filter(regex='_predicted')\n",
    "\n",
    "    # トライアルごとに特徴量を抽出し、PCAで次元削減し、クラス分類\n",
    "    train_classes = []\n",
    "    train_classes_true = []\n",
    "    test_classes = []\n",
    "\n",
    "    train_probs = []\n",
    "    train_probs_true = []\n",
    "    test_probs = []\n",
    "    \n",
    "    num_trials = len(train_predicted_woCatg) // 30  # 各trialには30点のデータがある\n",
    "    \n",
    "    for trial_index in range(num_trials):\n",
    "        # 該当するtrialのデータを取得\n",
    "        start_idx = trial_index * 30\n",
    "        end_idx = start_idx + 30\n",
    "        train_predicted_woCatg_data = train_predicted_woCatg.iloc[start_idx:end_idx].to_numpy()\n",
    "        train_predicted_woCatg_data_true = train_predicted_woCatg_true.iloc[start_idx:end_idx].to_numpy()\n",
    "        test_predicted_woCatg_data = test_predicted_woCatg.iloc[start_idx:end_idx].to_numpy()\n",
    "    \n",
    "        vel_x = train_predicted_woCatg_data[:,0]\n",
    "        vel_y = train_predicted_woCatg_data[:,1]\n",
    "        vel_z = train_predicted_woCatg_data[:,2]\n",
    "        vel_x_true = train_predicted_woCatg_data_true[:,0]\n",
    "        vel_y_true = train_predicted_woCatg_data_true[:,1]\n",
    "        vel_z_true = train_predicted_woCatg_data_true[:,2]\n",
    "        vel_x_test = - test_predicted_woCatg_data[:,0] # x,yは反転\n",
    "        vel_y_test = - test_predicted_woCatg_data[:,1] # x,yは反転\n",
    "        vel_z_test = test_predicted_woCatg_data[:,2]\n",
    "        \n",
    "    \n",
    "        # 特徴量を抽出\n",
    "        features = extract_features(vel_x, vel_y, vel_z)\n",
    "        features_true = extract_features(vel_x_true, vel_y_true, vel_z_true)\n",
    "        features_test = extract_features(vel_x_test, vel_y_test, vel_z_test)\n",
    "    \n",
    "        # PCAで次元削減\n",
    "        principal_components = pca.transform([features])  # 事前にfit_transformされたPCAを使用\n",
    "        principal_components_true = pca.transform([features_true])  # 事前にfit_transformされたPCAを使用\n",
    "        principal_components_test = pca.transform([features_test])  # 事前にfit_transformされたPCAを使用\n",
    "    \n",
    "        # GMMで分類\n",
    "        train_class = gmm.predict(principal_components)\n",
    "        train_classes.append(train_class)  # 分類結果をリストに追加\n",
    "        train_prob = gmm.predict_proba(principal_components)\n",
    "        train_probs.append(train_prob)  # 分類結果をリストに追加\n",
    "        \n",
    "        train_class_true = gmm.predict(principal_components_true)\n",
    "        train_classes_true.append(train_class_true)  # 分類結果をリストに追加\n",
    "        train_prob_true = gmm.predict_proba(principal_components_true)\n",
    "        train_probs_true.append(train_prob_true)  # 分類結果をリストに追加\n",
    "\n",
    "        test_class = gmm.predict(principal_components_test)\n",
    "        test_classes.append(test_class)  # 分類結果をリストに追加\n",
    "        test_prob = gmm.predict_proba(principal_components_test)\n",
    "        test_probs.append(test_prob)  # 分類結果をリストに追加\n",
    "    \n",
    "    # 分類結果の出力\n",
    "    all_train_classes.extend(train_classes)\n",
    "    all_train_classes_true.extend(train_classes_true)\n",
    "    all_test_classes.extend(test_classes)\n",
    "\n",
    "    all_train_probs.extend(train_probs)\n",
    "    all_train_probs_true.extend(train_probs_true)\n",
    "    all_test_probs.extend(test_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ca28d-8f45-49d2-9b80-fe9a3758dfd6",
   "metadata": {},
   "source": [
    "### trainの事前分類、予測後の一致率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5edfa0-d02d-4b96-bfab-5ff0e7f0f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一致する要素の数を数え、一致率を計算\n",
    "matching_count = sum([1 for a, b in zip(all_train_classes, all_train_classes_true) if a == b])\n",
    "total_count = len(all_train_classes)\n",
    "match_percentage = (matching_count / total_count) * 100\n",
    "\n",
    "match_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02620206-c1f7-46ea-bb9f-0aa92f818384",
   "metadata": {},
   "source": [
    "### trainの予測後、testの予測後の一致率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed9f012-6227-41c8-ad46-165464d4d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一致する要素の数を数え、一致率を計算\n",
    "matching_count = sum([1 for a, b in zip(all_train_classes, all_test_classes) if a == b])\n",
    "total_count = len(all_train_classes)\n",
    "match_percentage = (matching_count / total_count) * 100\n",
    "\n",
    "match_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a44fa3d-36d7-465d-b532-ee6e5569ea89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65c7c228-ac63-4194-890b-2b6e1ea864ea",
   "metadata": {},
   "source": [
    "# クラス分類結果を出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb01d93-1fdf-4272-bdc1-6cfd8b6519d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(output_folder, exp_name, f'all_train_classes.csv'), all_train_classes,  fmt=\"%s\")\n",
    "np.savetxt(os.path.join(output_folder, exp_name, f'all_train_classes_true.csv'), all_train_classes_true,  fmt=\"%s\")\n",
    "np.savetxt(os.path.join(output_folder, exp_name, f'all_test_classes.csv'), all_test_classes,  fmt=\"%s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d23a3ce-dfb5-475d-8fc5-181953b62988",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_train_probs_array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprob\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_train_probs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, exp_name, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_train_probs.csv\u001b[39m\u001b[38;5;124m'\u001b[39m), all_train_probs_array, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%.18e\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m all_train_probs_true_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([prob[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m prob \u001b[38;5;129;01min\u001b[39;00m all_train_probs_true])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/shape_base.py:289\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    288\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "all_train_probs_array = np.vstack([prob[0] for prob in all_train_probs])\n",
    "np.savetxt(os.path.join(output_folder, exp_name, f'all_train_probs.csv'), all_train_probs_array, delimiter=\",\", fmt=\"%.18e\")\n",
    "\n",
    "all_train_probs_true_array = np.vstack([prob[0] for prob in all_train_probs_true])\n",
    "np.savetxt(os.path.join(output_folder, exp_name, f'all_train_probs_true.csv'), all_train_probs_true_array, delimiter=\",\", fmt=\"%.18e\")\n",
    "\n",
    "all_test_probs_array = np.vstack([prob[0] for prob in all_test_probs])\n",
    "np.savetxt(os.path.join(output_folder, exp_name, f'all_test_probs.csv'), all_test_probs_array, delimiter=\",\", fmt=\"%.18e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3263d149-e54f-4717-b948-f12465ecc7ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_train_probs_true_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mall_train_probs_true_array\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_train_probs_true_array' is not defined"
     ]
    }
   ],
   "source": [
    "all_train_probs_true_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c51c110-69a6-4c31-a501-d9fe4053335d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd410d74-6d70-4294-bb80-ccf09296d3b0",
   "metadata": {},
   "source": [
    "ここまで"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b323f8ee-66c5-4291-91c2-dc4d2ceb0006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9543d1-b8af-4a6a-977f-9ff05ffc4a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695496a0-4133-4ae5-8fae-1b7ef6a3a8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1befe2-58cb-41bb-a256-ce1eb156e3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f440d4b-38d5-4900-8b3b-24d87b617545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d596e8-e5ed-4e46-b010-ed7188036285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14398171-3ce7-4e5a-9126-bf001767da02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95784e-a93a-4643-8121-30edcbac7081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d11692-d5f9-4c18-9689-dd8064dc172c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
